我们的排期大约在2月底，  
  
  1、基于距离（余弦相似度）的判别识别
数据：待检测——葡萄牙数据集中各个领域的70%数据；
编码方式：基于多语种的mbert、基于词频的tf-idf；
降维→PCA，对于bert编码的762维向量，降维到80/90维基本保留90%方差，
距离度量：余弦相似度、欧式距离（很慢）；
通过计算组内距离以及待识别文本与组内阈值的比值，分别探索0.7-1之间的过滤比例；
0.7——基本的过滤在<2%左右；
0.8——基本过滤在10%左右；
0.9——基本过滤在30%左右；
1——基本过滤在50%左右；

  
## 永琪的周报  
12.30~1.05  
1、对接资源语音部语音交互组，陆续开展相关工作；  
2、调研AI伪造数据相关检测方法；  
3、对接多语种生成数据鉴伪需求，编写数据规整脚本，准备开展相关数据试验；  
a、对齐伪造数据的评判标准（当前主要为句式重复）；  
4、挖掘巴西葡萄牙语标准数据集JJJR领域的编解码向量特征信息  
  
1.06~1.12  
1、进行[[无监督距离判别]]的AI伪造识别试验：  
a、划分测试集训练集，文本数据清洗规整；  
b、编码：分别采用了[[mbert]]以及[[TF-IDF算法]]两种编码进行测试  
c、对于巴西葡萄牙语标准集进行了抽样[[一致性检验]]；（不同编码后均一致）  
d、采用[[主成分分析（Principal components analysis）PCA]]对编码向量进行降维；  
e、根据待检测文本向量与标准集组内平均距离比值进行判别；（距离采用[[余弦相似度]]）  
2、对于[[高频gram（句式）筛选]]；  
a、采用了[[Jaccard相似系数]]相似度筛选不连续gram，tf-idf矩阵筛选连续gram；  
b、对子集gram进行去重，并取两者交集；  
c、基于高频gram进行筛选，对于不同参数的提取的gram，在句式重复的数据中识别结果达到90%左右，标准集数据不同领域达到0-10%之间不等；（存在内存不足问题）  
  
1.12~1.16  
1、对于[[超参数]]的[[消融实验]]；  
2、对于内存问题的优化；  
3、对于——待检测葡萄牙语进行第一版测试；